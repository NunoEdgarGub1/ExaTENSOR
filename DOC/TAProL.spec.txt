Tensor Algebra Programming Language (TAProL) Specification
AUTHOR: Dmitry I. Lyakh (Liakh): quant4me@gmail.com, liakhdi@ornl.gov
REVISION: 2018-10-15

Copyright (C) 2016 Dmitry I. Liakh.
Copyright (C) 2016 Oak Ridge National Laboratory, UT-Battelle, LLC.


0. PREAMBULE

TAProL is a high-level concise programming language for expressing tensor algebra computations,
that is, numeric operations performed on individual tensors and their aggregates.


1. TAProL PROGRAM STRUCTURE

A TAProl program, written in one or more source files with extension .tapl, is a collection
of "Scopes" with a single "Entry Point". The Entry Point specifies the first Scope to interpret.
Each Scope contains TAProl code. A Scope can call another Scope which will return to the
next line after finishing. By default, the objects defined within a specfic Scope are only
visible in that Scope. To pass objects from one Scope to another Scope the "Exchange Space"
needs to be used. The Exchange Space contains named objects for exchange between Scopes,
together with their access permissions. An object can be Exported from one Scope into the
Exchange Space with the user-defined permissions and subsequently Imported by another Scope,
provided that the latter has matching access permissions. Thus, different Scopes may depend
on each other only via data dependencies. In the following text, names in angle
brackets <> are supposed to be substituted by the corresponding content. A list of
keywords separated by "|" within a pair of curly brackets {} provides alternatives
among which a specific one needs to be chosen by the programmer. All user-defined
names in TAProl may only contain alphanumeric characters and underscore "_", and
they must begin with a letter character.

Scope specification:

 scope <scope_name> group(<group_name>,<group_name>,...)
  <TAProl_code>
 end scope <scope_name>

 The comma-separated list of <group_name> specifies which logical
 groups the Scope belongs to. Each Scope always belongs to its
 default (own) group, which has the same name as the Scope, as well
 as to the global group called "global" which contains all Scopes.
 Example:
  scope my_scope group()
  end scope my_scope
 Example:
  scope my_scope group(DMRG,CC)
  end scope my_scope

Entry Point specification:
 entry: <scope_name>

 The Entry Point must be specified before any Scope and only once accross all source files.


2. TAProl LANGUAGE CONSTRUCTS

2.1. Basic declarations:

Vector space specification:

 space({real|complex}): <space0_name> = <range0>, <space1_name> = <range1>, ...

 where
  {real|complex} is the selector between the Real or Complex number fields;
  <rangeX> is the dimension of the vector space <spaceX_name> in the form [<first>:<last>],
  where
   <first> and <last> define the numeration of the basis vectors, and the actual
   dimension of the space is (<last>-<first>+1). <first> and <last> can either be
   numeric literals or alphanumeric identifiers (with at least one letter).
   In the latter case, these identifiers will be dereferenced from the Exchange Space
   assuming that they are available there (if not, the program will fail).
 Example:
  space(complex): space1=[0:947], space2=[1:upper_limit2]

Vector subspace specification:

 subspace(<space_name>): <subspace0_name> = <range0>, <subspace1_name> = <range1>, ...

 where
  <space_name> is the name of the parental vector space defined by the "space" statement;
  <rangeX> is the subrange of basis vectors which define the subspace being declared in
  the form [<first>:<last>], analogously with the above description for the "space" statement.
 Example:
  space(real): space1=[0:947]
  subspace(space1): subspace0=[13:134], subspace1=[lower1:upper1]

Index specification (placeholder for a given subspace):

 index(<subspace_name>): <index_name>,<index_name>, ...

 where
  <subspace_name> is the name of the corresponding subspace defined by the "subspace" statement.
  Each index defined in this way is associated with subspace <subspace_name>.
 Example:
  space(real): space1=[0:947]
  subspace(space1): subspace0=[13:134], subspace1=[lower1:upper1]
  index(subspace0): i,j,k,l1
  index(subspace1): a1,b1,c2,d

Index inheritance:
 One can also define an index by inheriting the properies from another already defined index, like:
 index: b1=a1, b2=a2
 Here indices b1 and b2 will bind to the same subspaces as a1 and a2, respectively.


2.2. Tensor creation and destruction:

A tensor is specified via its alphanumeric name (at least one letter) and a comma-separated
list of indices enclosed in parentheses: <tensor_name>(<index>,<index>,...). No space is
allowed between the tensor name and the left parenthesis. A scalar tensor is specified as <scalar_name>().
Each index associates its subspace with the corresponding tensor dimension. The total number of tensor
dimensions (total number of tensor indices) is called the tensor rank (or order). The subspace associated
with a specific tensor dimension determines the range of that tensor dimension. The dimension of
the subspace determines the extent of the corresponding tensor dimension.
Examples of tensors: S34(a1,b,c3), TT(i,j,k,l), SS1().

Explicit creation with initialization:

 1) <tensor> = <numeric_value>
    If <numeric_value> is a numeric literal, then all tensor elements will be assigned
    that specific numeric value. If <numeric_value> is an alphanumeric identifier,
    it will be dereferenced from the Exchange Space, provided it is there. Examples:
    T3(i1,u,w23,k) = 0
    W2(k,l,m) = init_value1

 2) <tensor> = method("<method_name>")
    where "<method_name>" is a symbolic name of the corresponding user-defined function
    used to initialize the tensor right after its creation. Example:
    RR(i,j,k,l,m) = method("Init_my_tensor")

 3) load <tensor>: tag("<stored_name>")
    This statement will either load a full tensor or a specific tensor slice from the
    persistent storage space where the tensor is marked by its "<stored_name>". Examples:
    load S2(i,j,k): tag("My old tensor")
    If a tensor index has already been defined, its range must match the stored value.
    If a tensor index is undefined, it will become defined from the stored value.

Explicit creation without initialization:

 <tensor> = ?

 For example: T2(a,b,c,d) = ?

Explicit creation with deferred initialization:

 <tensor> => method("<method_name>")

 The tensor is created, but its initialization by method "<method_name>" is
 postponed until it is used for the first time after its creation. Examples:
 Y12(j,m,n,k) => method("My deferred init method")

 Besides explicit construction, a tensor will be constructed implicitly when
 it is undefined while being the result of a tensor operation.

Index symmetry restrictions:

 Optionally, one can specify index symmetry restrictions during tensor creation,
 except for the "load" statement. The index symmetry restrictions are appended
 at the end of the creation/initalization statement after a colon, for example:

 T2(a,b,i,j,k) = 0: [a<b] [i<j<k]
 MM(a,b) = 0: [a<b]

 In this case, only the tensor parts satisfying these conditions will be created.
 In particular, MM(a,b) will be created as a triangular matrix. Index symmetry
 restrictions can also be specified during indirect tensor creation in a tensor
 operation (when a previously undefined tensor appears as a result of the operation).

Explicit destruction:

 ~{<tensor>|<tensor_name>}

 OR

 destroy {<tensor>|<tensor_name>},{<tensor>|<tensor_name>},...

 Both forms are equivalent, except the latter can be applied to multiple tensors simultaneously.
 If a tensor is specified by its <tensor_name>, then the entire tensor will be destroyed.
 Optionally, by providing tensor indices in <tensor>, only the specific slice will be destroyed.
 Examples:
 ~Y13
 ~T4(i,j,k)
 destroy R5
 destroy F3(m,n,k)
 destroy C4,TT(i,j,l)

A tensor can be stored in persistent storage by the following statement:

 save <tensor>: tag("<stored_name>")

 The tag "<stored_name>" associated with the tensor in the persistent storage can
 later be used for loading it back via the "load" statement.


2.3. Tensor operations:

A tensor operation is a well-defined numerical primitive operating on tensors
or tensor slices. The resulting tensor is allowed to be undefined beforehand,
in which case it will be created and defined as a result of the tensor operation.
Each tensor in a tensor operation may additionally be complex conjugated via
adding "+" right after the tensor name prior to the left parenthesis, for example:
S34+(a,b,c,d)

Currently defined tensor operations:

 1) Assignment:
    <tensor> = <numeric_value>
    <tensor> = method("<method_name>")
    Examples:
    T1(i,j,k,l) = 0
    T1(i,j,k,l) = new_value
    T1(i,j,k,l) = method("Init my tensor")
    In the second example, new_value will be looked up in the Exchange Space, if there.

 2) Permutation of tensor dimensions:
    <tensor0> = <tensor1>
    Examples:
    T1(i,j,k,l) = S1(k,j,l,i)

 3) Scaling:
    <tensor> *= <numeric_value>
    Examples:
    T1(i,j,k,l) *= 1.13
    T1(i,j,k,l) *= my_factor
    In the second example, my_factor will be looked up in the Exchange Space, if there.

 4) Folding (dimension flattening):
    <tensor0> = <tensor1>
    Examples:
    S1(a,k) = T1(i,j,k,l)
    Here dimensions i, j, l of T1 will be combined into dimension a=(i,j,l) of S1.

 5) Unfolding (dimension expansion):
    <tensor0> = <tensor1>
    Examples:
    T1(i,j,k,l) = S1(a,k)
    Here dimension a of S1 is unfolded into three dimensions of T1, namely, i,j,l.

 6) Addition:
    <tensor0> += <tensor1> {|* <numeric_value>}
    Examples:
    T1(i,j,k,l) += S1(j,k,i,l)
    T1(i,j,k,l) += S1(i,j,k,l) * -1.13
    T1(i,j,k,l) += S1(j,k,i,l) * my_factor
    In the third example, my_factor will be looked up in the Exchange Space, if there.

 7) Product:
    <tensor0> += <tensor1> * <tensor2> {|* <numeric_value>}
    where <tensor1> and <tensor2> do not have indices in common.
    Examples:
    T1(i,j,k,l) += S1(k,j) * S2(i,l)
    T1(i,j,k,l) += S1(i,j) * S2(k,l) * -1.13
    T1(i,j,k,l) += S1(k,j) * S2(i,l) * my_factor
    In the third example, my_factor will be looked up in the Exchange Space, if there.

 8) Contraction:
    <tensor0> += <tensor1> * <tensor2> {|* <numeric_value>}
    where <tensor1> and <tensor2> have indices in common (contracted indices).
    Examples:
    T1(i,j,k,l) += S1(k,c,j,d) * S2(c,i,l,d)
    T1(i,j,k,l) += S1(k,c,j,d) * S2(d,i,c,l) * -1.13
    T1(i,j,k,l) += S1(k,c,j,d) * S2(c,i,l,d) * my_factor
    In the third example, my_factor will be looked up in the Exchange Space, if there.


2.4. Tensor network specification:

A tensor network is a contraction of two or more tensors. It can be specified as (example):
 TN(i,j,k,l) => F1(i,a) * F2(a,j,b) * F3(b,k,c) * F4(c,l)
 Here TN(i,j,k,l) is just a placeholder for the tensor contraction defined on the r.h.s.
 Whenever TN(i,j,k,l) is encountered in a tensor expression, it will be expanded accordingly.

A tensor network specification can be used for defining tensor decompositions, for example:
 TN(i,j,k,l) = S13(i,j,k,l)
 where TN(i,j,k,l) is a tensor network placeholder, for example the one above. This statement
 will factorize the tensor S13(i,j,k,l) according to the structure of TN(i,j,k,l).
 Example (SVD decomposition):
  TN(i,j,k,l) => F1(i,j,d) * F2(d,k,l)
  TN(i,j,k,l) = S13(i,j,k,l)
  Here the tensor S13(i,j,k,l) will be decomposed into F1(i,j,d) * F2(d,k,l).


2.5. Passing control to other Scopes and data exchange between Scopes:

A Scope can be invoked from another Scope by the following statement:

 invoke <scope_name>

 After finishing, the invoked Scope will pass control back to the
 statement following "invoke ...".

To pass data between Scopes, the following statements are used:

 export <tensor>: tag("<external_tag>") to(<group_name>:<access>,<group_name>:<access>,...)

 This will expose a tensor (or a tensor slice) <tensor> to the Exchange Space
 under a unique name <external_tag>. All Scopes belonging to either group from
 the comma-separated list will be able to access the tensor via the "import" statement:

 import <tensor>: tag("<external_tag>")

 The "import" statement is semantically equivalent to the "load" statement,
 except that "import" only associates the data between different Scopes whereas
 "load" actually loads the data from the persistent storage.
 <access> parameters in the "export" statement regulate the access permissions for each
 group the tensor is exported to, taking the following possible values:
 "r" which means Read Only;
 "w" which means Read-and-Write;
